{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd8e310",
   "metadata": {},
   "source": [
    "# Woolsey Fire linear regressions\n",
    "\n",
    "This notebook calculates linear regressions between data related to the Woolsey Fire. The notebook produces a large number of plots, so figures are saved to disk instead of displayed inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy_groupies as npg\n",
    "import rioxarray as rxr\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "\n",
    "from ea_drought_burn.config import CRS\n",
    "from ea_drought_burn.utils import (\n",
    "    aggregate,\n",
    "    create_figure,\n",
    "    create_sampling_mask,\n",
    "    open_raster,\n",
    "    plot_bands,\n",
    "    plot_rgb,\n",
    "    plot_regression,\n",
    "    reproject_match\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set whether to plot prefire or postfire data. Used to set the boundary of\n",
    "# the study area and the response variables plotted.\n",
    "DATA_TO_PLOT = \"postfire\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set default plotting parameters\n",
    "plt.rc(\"figure.constrained_layout\", use=True, h_pad=12/72, w_pad=12/72)\n",
    "\n",
    "# Set working directory to the earthpy data directory\n",
    "os.chdir(os.path.join(et.io.HOME, \"earth-analytics\", \"data\", \"woolsey-fire\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ba3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_burned(xda, burned):\n",
    "    \"\"\"Calculates array to mask pixels based on if they burned\"\"\"\n",
    "    if burned.lower() == \"burned\":\n",
    "        return xr.where(xda >= 100, True, False).values\n",
    "    return xr.where(xda < 100, True, False).values\n",
    "        \n",
    "    \n",
    "def mask_community(xda, name):\n",
    "    \"\"\"Calculates array to mask everything except the given community\"\"\"\n",
    "    names = {\n",
    "        \"All communities\": None,\n",
    "        \"Annual grass\": 1,\n",
    "        \"Chaparral\": 2,\n",
    "        \"Coastal sage scrub\": 3,\n",
    "        \"Oak woodland\": 4,\n",
    "        \"Riparian\": 5,\n",
    "        \"Substrate\": 6\n",
    "    }\n",
    "    if names[name] is None:\n",
    "        return xr.where(xda == names[name], True, True).values\n",
    "    return xr.where(xda == names[name], True, False).values\n",
    "\n",
    "\n",
    "def mask_aspect(xda, aspect):\n",
    "    \"\"\"Calculates array to mask everything except the given aspect\"\"\"\n",
    "    try:\n",
    "        i = [\"E\", \"S\", \"W\"].index(aspect)\n",
    "    except ValueError:\n",
    "        return xr.where((xda > 315) | (xda <= 45), True, False)\n",
    "    else:\n",
    "        mindeg =  + 90 * i\n",
    "        maxdeg = mindeg + 90\n",
    "        return xr.where((xda > mindeg) & (xda <= maxdeg), True, False)\n",
    "\n",
    "    \n",
    "def mask_slope(xda, steepness=\"flat\"):\n",
    "    \"\"\"Calculates array to mask everything except the given steepness\"\"\"\n",
    "    # FIXME: Bin these better\n",
    "    steepnesses = {\n",
    "        \"flat\": (0, 10),\n",
    "        \"shallow\": (10, 30),\n",
    "        \"steep\": (30, 90)\n",
    "    }\n",
    "    minslope, maxslope = steepnesses[steepness.lower()]\n",
    "    return xr.where((xda > minslope) & (xda <= maxslope), True, False)\n",
    "\n",
    "\n",
    "def slugify(val):\n",
    "    return re.sub(\" +\", \"_\", val.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DATA_TO_PLOT\n",
    "if DATA_TO_PLOT not in {\"prefire\", \"postfire\"}:\n",
    "    raise ValueError(\"DATA_TO_PLOT must be either prefire or postfire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78814957",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Woolsey Fire perimeter\n",
    "woolsey_fire = gpd.read_file(os.path.join(\"shapefiles\",\n",
    "                                          \"nifc_woolsey_perimeter\",\n",
    "                                          \"2018-CAVNC-091023.shp\")).to_crs(CRS)\n",
    "crop_bound = woolsey_fire.geometry\n",
    "\n",
    "# Pre-fire plots use the fire envelope, post-fire plots use the fire scar\n",
    "if DATA_TO_PLOT == \"prefire\":\n",
    "    crop_bound = woolsey_fire.envelope.geometry\n",
    "elif DATA_TO_PLOT == \"postfire\":\n",
    "    crop_bound = woolsey_fire.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open SMM stack\n",
    "smm_stack = open_raster(\n",
    "    os.path.join(\"aviris-climate-vegetation\", \"SMMDroughtstack.dat\"),\n",
    "    crs=CRS,\n",
    "    crop_bound=crop_bound,\n",
    ")\n",
    "smm_stack = smm_stack.where(smm_stack >= -1e38)\n",
    "\n",
    "# Calculate fraction dead from fraction alive\n",
    "fal = smm_stack[1:5]\n",
    "minfal, maxfal = np.nanpercentile(fal, (1, 99))\n",
    "fal = fal.where((fal > minfal) & (fal < maxfal))\n",
    "fdd = 1 - fal\n",
    "\n",
    "# Calculate dFAL as pre- minus post-fire FAL. Positive values indicate loss\n",
    "# of living vegetation. Align dFAL with the second year of the range for each\n",
    "# (for example, align 2013-2014 to 2014). The first array is therefore empty. \n",
    "dfal = []\n",
    "dfal.append(fal[0].where(~np.isfinite(fal[0])))  # first band is all NaN\n",
    "dfal.append(fal[0] - fal[1])\n",
    "dfal.append(fal[1] - fal[2])\n",
    "dfal.append(fal[2] - fal[3])\n",
    "for i, band in enumerate(dfal):\n",
    "    band[\"band\"] = i + 1\n",
    "dfal = xr.concat(dfal, dim=\"band\")\n",
    "\n",
    "# Calculate fraction dead since each of the four years in the dataset. For\n",
    "# each pixel, calculate the minmum fraction dead between the current year\n",
    "# and the end of the dataset, then subtract the fraction dead from the\n",
    "# preceding year.\n",
    "dead_since = []\n",
    "dead_since.append(fdd[:3].min(axis=0))\n",
    "dead_since.append(fdd[1:3].min(axis=0) - fdd[0])\n",
    "dead_since.append(fdd[2:3].min(axis=0) - fdd[1])\n",
    "dead_since.append(fdd[3:].min(axis=0) - fdd[2])\n",
    "for i, band in enumerate(dead_since):\n",
    "    band[\"band\"] = i + 1\n",
    "dead_since = xr.concat(dead_since, dim=\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dNBR from MTBS \n",
    "path = os.path.join(\"mtbs-burn-severity\",\n",
    "                    \"ca3424011870020181108\",\n",
    "                    \"ca3424011870020181108_20171215_20181215_dnbr.tif\")\n",
    "dnbr = open_raster(path, crs=CRS)\n",
    "dnbr = dnbr.where(dnbr != -9999, np.nan)\n",
    "\n",
    "dnbr = reproject_match(dnbr, smm_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfa2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read slope data\n",
    "path = os.path.join(\"usgs-terrain\", \"usgs_2016_18_merge_rs15m_fix_slope.tif\")\n",
    "slope = open_raster(path)\n",
    "slope = reproject_match(slope, smm_stack[0])\n",
    "\n",
    "# Read aspect data\n",
    "path = os.path.join(\"usgs-terrain\", \"usgs_2016_18_merge_rs15m_fix_aspect.tif\")\n",
    "aspect = open_raster(path)\n",
    "aspect = reproject_match(aspect, smm_stack[0])\n",
    "\n",
    "# Calculate folded aspect\n",
    "folded_aspect = np.absolute(180 - np.absolute(aspect - 225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c217f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sampling mask\n",
    "sampling_mask = create_sampling_mask(\n",
    "    smm_stack[0],\n",
    "    counts={\"training\": 7000, \"validation\": 3000},\n",
    "    seed=20210421\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PRISM grid\n",
    "prism_grid = open_raster(\n",
    "    os.path.join(\"masks\", \"prism_grid.tif\"),\n",
    "    crs=CRS,\n",
    "    crop_bound=crop_bound,\n",
    "    masked=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82446b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lookup for full datasets\n",
    "datasets = {\n",
    "    # Vegetation community\n",
    "    \"Community\": smm_stack[0],\n",
    "    # Burn severity\n",
    "    \"dNBR\": dnbr,\n",
    "    # Fraction alive\n",
    "    \"FAL\": smm_stack[1:5],\n",
    "    \"dFAL\": dfal,\n",
    "    \"Dead Since\": dead_since,\n",
    "    # Topography\n",
    "    \"Aspect\": aspect,\n",
    "    \"Folded Aspect\": folded_aspect,\n",
    "    \"Slope\": slope,\n",
    "    # Drought climate\n",
    "    \"Days Precipitation\": smm_stack[5:9],\n",
    "    \"Max VPD\": smm_stack[9:13],\n",
    "    \"Min Temperature\": smm_stack[13:17],\n",
    "    \"Heat Days Over 95\": smm_stack[17:21],\n",
    "    \"Cumulative Precipitation\": smm_stack[21:25]\n",
    "}\n",
    "\n",
    "# Calculate subsets center around a cardinal direction\n",
    "for cdir, offset in [\n",
    "    (\"North\", 0),\n",
    "    (\"East\", 90),\n",
    "    (\"South\", 180),\n",
    "    (\"West\", 270),\n",
    "]:\n",
    "    aspect_rad = xr.apply_ufunc(np.deg2rad, datasets[\"Aspect\"] - offset)\n",
    "    datasets[f\"{cdir}ness\"] = xr.apply_ufunc(np.cos, aspect_rad.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723967cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all data has the same shape\n",
    "shapes = {\n",
    "    \"prism_grid\": prism_grid.shape[-2:],\n",
    "    \"sampling_mask\": sampling_mask.shape[-2:],\n",
    "}\n",
    "shapes.update({k: v.shape[-2:] for k, v in datasets.items()})\n",
    "if len(set([tuple(s) for s in shapes.values()])) != 1:\n",
    "    display(shapes)\n",
    "    raise ValueError(\"Shapes do not match\")\n",
    "\n",
    "# Verify that all data has the same bounds\n",
    "bounds = {\n",
    "    \"prism_grid\": prism_grid.rio.bounds(),\n",
    "    \"sampling_mask\": sampling_mask.rio.bounds(),\n",
    "}\n",
    "bounds.update({k: v.rio.bounds() for k, v in datasets.items()})\n",
    "if len(set([s for s in bounds.values()])) != 1:\n",
    "    display(bounds)\n",
    "    raise ValueError(\"Bounds do not match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training subset\n",
    "training = {k: v.where(sampling_mask[0]) for k, v in datasets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1bd81",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This box creates A LOT of plots, so don't show them\n",
    "%matplotlib agg\n",
    "\n",
    "def plot_regressions(\n",
    "    xdata,\n",
    "    ydata,\n",
    "    subsets=None,\n",
    "    agg_to=None,\n",
    "    xagg=np.nanmean,\n",
    "    yagg=np.nanmean,\n",
    "    colors=None,\n",
    "    titles=None,\n",
    "    outdir=None,\n",
    "    use_one_figure=True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Plots a set of regressions\"\"\"\n",
    "    \n",
    "    # Set maplotlib params\n",
    "    plt.rc(\"font\", size=24)\n",
    "    plt.rc(\"axes\", labelsize=24)\n",
    "    plt.rc(\"xtick\", labelsize=24)\n",
    "    plt.rc(\"ytick\", labelsize=24)\n",
    "    plt.rc(\"legend\", fontsize=24)\n",
    "    plt.rc(\"figure.constrained_layout\", use=True, h_pad=12/72, w_pad=12/72)\n",
    "    \n",
    "    subset_names = list(subset.keys())\n",
    "    subset_data = list(subsets.values())\n",
    "\n",
    "    # Default is that each key gets its own column\n",
    "    for data in (xdata, ydata):\n",
    "        if isinstance(data, dict):\n",
    "            n_cols = len(data.keys())\n",
    "            break\n",
    "    else:\n",
    "        n_cols = 1\n",
    "    \n",
    "    # Combine all plots into a single figure\n",
    "    if use_one_figure:\n",
    "        \n",
    "        # Get the number of options in each subset\n",
    "        n_items = [len(s[2]) for s in subset_data]\n",
    "        \n",
    "        # If only one key, set number of columns based on items in first subset\n",
    "        if n_cols == 1:\n",
    "            try:\n",
    "                n_cols = n_items[0]\n",
    "                n_items = n_items[1:]\n",
    "            except (IndexError, TypeError, ValueError):\n",
    "                pass\n",
    "            \n",
    "        #print(2, n_cols)\n",
    "        \n",
    "        # Set number of rows based on total number of subsets\n",
    "        try:\n",
    "            n_rows = np.product(n_items)\n",
    "            # If only one column, plot everything in one row instead\n",
    "            if n_cols == 1:\n",
    "                n_cols = n_rows\n",
    "                n_rows = 1\n",
    "        except (IndexError, TypeError, ValueError):\n",
    "            n_rows = 1\n",
    "            \n",
    "        #print(3, n_rows, n_cols)\n",
    "        \n",
    "        fig, axes = create_figure(n_rows, n_cols)\n",
    "    \n",
    "    # Otherwise, calculate the total number of plots needed to convey each\n",
    "    # plot from the primary subset\n",
    "    else:\n",
    "        try:\n",
    "            n_rows = np.product([len(s[2]) for s in subset_data[1:]])\n",
    "        except ValueError:\n",
    "            n_rows = 1\n",
    "            \n",
    "    # Set up the figure based on the first entry\n",
    "    if subsets:\n",
    "        func, xda, args = subset_data[0]\n",
    "    else:\n",
    "        func, xda, args = None, None, [None]\n",
    "        \n",
    "    # Colors default to black if none supplied\n",
    "    if colors is None:\n",
    "        colors = [\"black\"] * len(args)\n",
    "    \n",
    "    # Titles default to \"Untitled\" if none supplied\n",
    "    if titles is None:\n",
    "        titles = [\"Untitled\"] * len(args)\n",
    "\n",
    "    for arg, color, title in zip(args, colors, titles):\n",
    "        \n",
    "        if not use_one_figure:\n",
    "            fig, axes = create_figure(n_rows, n_cols, title)\n",
    "        \n",
    "        # Create mask from primary subset if defined\n",
    "        if xda is not None:\n",
    "            mask = func(xda, arg) if func else xda.copy()\n",
    "        else:\n",
    "            mask = None\n",
    "        \n",
    "        try:\n",
    "            combinations = itertools.product(*[s[2] for s in subset_data[1:]])\n",
    "        except (TypeError, ValueError):\n",
    "            combinations = [None]\n",
    "\n",
    "        # Walk through each subset if subsets defined\n",
    "        for args in combinations:\n",
    "\n",
    "            # Combine masks for each subset into a single mask\n",
    "            subset_mask = None\n",
    "            subtitle = \"\"\n",
    "            if mask is not None:\n",
    "                subset_mask = mask.copy()\n",
    "                filters = []\n",
    "                for (func_, xda_, _), arg in zip(subset_data[1:], args):\n",
    "                    subset_mask *= func_(xda_, arg) if func_ else xda_\n",
    "                    filters.append(arg)\n",
    "                subtitle = ', '.join([str(s) for s in filters])\n",
    "\n",
    "            # Either xdata, ydata, or both can be dicts. If only one is a\n",
    "            # dict, plot each key against the other array. If both are dicts,\n",
    "            # their keys must match.\n",
    "            keys = []\n",
    "            for data in (xdata, ydata):\n",
    "                if isinstance(data, dict):\n",
    "                    keys.extend(data.keys())\n",
    "            \n",
    "            for key in sorted(set(keys if keys else [None])):\n",
    "                \n",
    "                # Read x and y data\n",
    "                if isinstance(xdata, dict):\n",
    "                    x = xdata[key].copy()\n",
    "                else:\n",
    "                    x = xdata.copy()\n",
    "                    \n",
    "                if isinstance(ydata, dict):\n",
    "                    y = ydata[key].copy()\n",
    "                else:\n",
    "                    y = ydata.copy()\n",
    "                    \n",
    "                # Mask any non-finite value in subset, x, or y\n",
    "                if subset_mask is not None:\n",
    "                    x = x.where(subset_mask)\n",
    "                    y = y.where(subset_mask)\n",
    "                \n",
    "                # Calculate blocks aligned with a reference grid\n",
    "                if agg_to is not None:\n",
    "                    try:\n",
    "                        x = aggregate(x, agg_to, func=xagg)\n",
    "                        y = aggregate(y, agg_to, func=yagg)\n",
    "                    except (IndexError, ValueError):\n",
    "                        raise ValueError(\n",
    "                            f\"Aggregation failed: agg_to={agg_to.shape},\"\n",
    "                            f\" x={x.shape}, xlabel={xlabel},\"\n",
    "                            f\" y={y.shape}, ylabel={ylabel}\"\n",
    "                        )\n",
    "                \n",
    "                # Convert to 1D arrays\n",
    "                x = np.ravel(x)\n",
    "                y = np.ravel(y)\n",
    "                \n",
    "                # Limit to values that are finite in both arrays\n",
    "                xy_mask = x * y\n",
    "                x = x[np.isfinite(xy_mask)]\n",
    "                y = y[np.isfinite(xy_mask)]\n",
    "                \n",
    "                # Set axis title\n",
    "                ax_title = f\"{ylabel} vs. {xlabel}\"\n",
    "                if key != xlabel or title:\n",
    "                    vals = [\n",
    "                        \"Agg\" if agg_to is not None else \"\",\n",
    "                        key if key != xlabel else \"\",\n",
    "                        title\n",
    "                    ]\n",
    "                    val = \" - \".join([str(s) for s in vals if s])\n",
    "                    if val:\n",
    "                        ax_title += \"\\n\" + val\n",
    "                if subtitle:\n",
    "                    ax_title += f\"\\n({subtitle})\"\n",
    "                ax_title = ax_title.replace(\"\\n\\n\", \"\\n\").strip()\n",
    "\n",
    "                # Plot regression\n",
    "                plot_regression(x, y, axes.pop(0),\n",
    "                                color=color,\n",
    "                                title=ax_title,\n",
    "                                **kwargs)\n",
    "\n",
    "        # Save plot to file if directory supplied and axes exhuasted\n",
    "        if outdir and not axes:\n",
    "            \n",
    "            try:\n",
    "                os.makedirs(outdir)\n",
    "            except OSError:\n",
    "                pass\n",
    "            \n",
    "            # Construct filename based on arguments\n",
    "            parts = [\n",
    "                \"\".join(subset_names) if subset_names else \"all\",\n",
    "                \"agg\" if agg_to is not None else \"pt\",\n",
    "                ylabel,\n",
    "                \"vs\",\n",
    "                xlabel\n",
    "            ]\n",
    "            if not use_one_figure:\n",
    "                parts.append(title)\n",
    "            stem = slugify(' '.join(parts)).strip(\"_\")\n",
    "            path = os.path.join(outdir, f\"{stem}.png\")\n",
    "            plt.savefig(path)\n",
    "            \n",
    "            # Remove figure instance\n",
    "            plt.close(fig)\n",
    "    \n",
    "    if axes:\n",
    "        raise ValueError(f\"{ylabel} vs {xlabel}\")\n",
    "    \n",
    "    # Reset matplotlib plotting params\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Set names and colors of vegetation communities\n",
    "communities = [\n",
    "    \"All communities\",\n",
    "    \"Annual grass\",\n",
    "    \"Chaparral\",\n",
    "    \"Coastal sage scrub\",\n",
    "    \"Oak woodland\",\n",
    "    \"Riparian\",\n",
    "    \"Substrate\"\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    \"black\",\n",
    "    \"tab:green\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "    \"tab:red\",\n",
    "    \"tab:blue\",\n",
    "    \"lightgray\"\n",
    "]\n",
    "\n",
    "# Define explanatory and response values to evaluate as (x, y)\n",
    "xy = {\n",
    "    # Vegetation mortality variables\n",
    "    #\"FAL\": [\"dNBR\"],\n",
    "    #\"dFAL\": [\"dNBR\"],\n",
    "    #\"Dead Since\": [\"dNBR\"],\n",
    "    # Climate variables\n",
    "    #\"Days Precipitation\": [\"dNBR\", \"dFAL\", \"FAL\"],\n",
    "    #\"Max VPD\": [\"dNBR\", \"dFAL\", \"FAL\"],\n",
    "    #\"Min Temperature\": [\"dNBR\", \"dFAL\", \"FAL\"],\n",
    "    #\"Heat Days Over 95\": [\"dNBR\", \"dFAL\", \"FAL\"],\n",
    "    #\"Cumulative Precipitation\": [\"dNBR\", \"dFAL\", \"FAL\"],\n",
    "    # Topography variables\n",
    "    \"Folded Aspect\": [\"dNBR\", \"dFAL\", \"FAL\"],\n",
    "    \"Slope\": [\"dNBR\", \"dFAL\", \"FAL\"]   \n",
    "}\n",
    "\n",
    "# Define parameters to use for plotting\n",
    "params = {\n",
    "    \"xydata\": [],\n",
    "    \"agg\": [True, False],\n",
    "}\n",
    "\n",
    "# Select y based on if we're plotting pre- or post-fire data\n",
    "for x, ys in xy.items():\n",
    "    for y in ys:\n",
    "        if (\n",
    "            DATA_TO_PLOT == \"prefire\" and y == \"dNBR\"\n",
    "            or DATA_TO_PLOT == \"postfire\" and y != \"dNBR\"\n",
    "        ):\n",
    "            continue\n",
    "        params[\"xydata\"].append((x, y))\n",
    "        \n",
    "# Calculate all possible combinations of params\n",
    "param_sets = list(itertools.product(*params.values()))\n",
    "\n",
    "# Define subsets that will be used to segment the data. Each subset will be\n",
    "# used for each set of parameters.\n",
    "subsets = {\n",
    "    \"c\": (mask_community, datasets[\"Community\"].copy(), communities[:-1]),\n",
    "    \"b\": (mask_burned, dnbr, [\"Burned\", \"Unburned\"]),\n",
    "    \"s\": (mask_slope, slope, [\"Flat\", \"Shallow\", \"Steep\"]),\n",
    "    \"a\": (mask_aspect, aspect, [\"N\", \"S\"])\n",
    "}\n",
    "\n",
    "# Calculate all possible combinations of subsets\n",
    "keys = list(subsets)\n",
    "subset_sets = [\"\"]\n",
    "for r in range(1, len(keys) + 1):\n",
    "    subset_sets.extend(itertools.combinations(keys, r))\n",
    "\n",
    "for xydata, agg in param_sets:\n",
    "\n",
    "    # Set data source (all data if aggregating, training otherwise)\n",
    "    lookup = datasets if agg else training\n",
    "    \n",
    "    # Get x and y data\n",
    "    xlabel, ylabel = xydata\n",
    "    \n",
    "    # Convert banded arrays to year-keyed dicts\n",
    "    xdata = lookup[xlabel].copy() \n",
    "    if len(xdata.shape) == 3:\n",
    "        xdata = dict(zip(range(2013, 2017), xdata))\n",
    "\n",
    "    ydata = lookup[ylabel].copy()\n",
    "    if len(ydata.shape) == 3:\n",
    "        ydata = dict(zip(range(2013, 2017), ydata))\n",
    "\n",
    "    # Iterate through each subset\n",
    "    for subset_keys in subset_sets:\n",
    "        \n",
    "        print(f\"Processing {ylabel} vs {xlabel} ({''.join(subset_keys)})...\")\n",
    "\n",
    "        # Check for subsets\n",
    "        if subset_keys:         \n",
    "            subset = {k: subsets[k] for k in subset_keys}\n",
    "            titles = subset[subset_keys[0]][2]\n",
    "        else:\n",
    "            subset = {}\n",
    "            titles = [\"\"]\n",
    "\n",
    "        # Skip subsets that use the same data as x\n",
    "        if (\n",
    "            xlabel in (\"Aspect\", \"Northness\", \"Eastness\") and \"a\" in subset\n",
    "            or xlabel == \"Slope\" and \"s\" in subset\n",
    "        ):\n",
    "            continue\n",
    "        \n",
    "        # Name output directories using the response variable\n",
    "        outdir = os.path.join(*[\"outputs\", \"plots\", DATA_TO_PLOT, ylabel])\n",
    "\n",
    "        # Style axes based on labels\n",
    "        kwargs = {}\n",
    "        if xlabel == \"FAL\":\n",
    "            kwargs[\"xlim\"] = (0, 1)\n",
    "        if ylabel == \"FAL\":\n",
    "            kwargs[\"ylim\"] = (0, 1)\n",
    "        if \"ness\" in xlabel:\n",
    "            kwargs[\"xlim\"] = (-1, 1)\n",
    "\n",
    "        plot_regressions(\n",
    "            xdata,\n",
    "            ydata,\n",
    "            subsets=subset,\n",
    "            agg_to=prism_grid if agg else None,\n",
    "            xagg=np.nanmean if xlabel != \"dFAL\" else np.nansum,\n",
    "            yagg=np.nanmean if ylabel != \"dFAL\" else np.nansum,\n",
    "            colors=colors if \"c\" in subset_keys else None,\n",
    "            titles=titles,\n",
    "            outdir=outdir,\n",
    "            xlabel=xlabel,\n",
    "            ylabel=ylabel,\n",
    "            **kwargs\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

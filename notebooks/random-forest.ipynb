{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43052e37",
   "metadata": {},
   "source": [
    "# Woolsey Fire Random Forest Model\n",
    "\n",
    "This random-forest model in this notebook seeks to model how pre-fire conditionsâ€”including vegetation, topography, and climateâ€”contributed to burn severity during the Woolsey Fire. The configuration and results of each run can be modified under the **Configure model** section and are saved when the run finishes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a52ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode\n",
    "from shapely.geometry import box\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    mean_squared_error,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import xarray as xr\n",
    "\n",
    "from ea_drought_burn.config import CRS\n",
    "from ea_drought_burn.utils import (\n",
    "    aggregate,\n",
    "    copy_xr_metadata,\n",
    "    create_figure,\n",
    "    create_sampling_mask,\n",
    "    hist,\n",
    "    load_nifc_fires,\n",
    "    open_raster,\n",
    "    plot_bands,\n",
    "    plot_rgb,\n",
    "    plot_regression,\n",
    "    reproject_match\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Set plot style\n",
    "plt.rc(\"figure.constrained_layout\", use=True, h_pad=12/72, w_pad=12/72)\n",
    "sns.set(font_scale=1.5, style=\"white\")\n",
    "\n",
    "# Set working directory to the earthpy data directory\n",
    "os.chdir(os.path.join(et.io.HOME, \"earth-analytics\", \"data\", \"woolsey-fire\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_format(num):\n",
    "    \"\"\"Formats float to a string\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num: int or float\n",
    "        number to format for print\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        number as a string\n",
    "    \"\"\"\n",
    "    return f\"{num:.3f}\" if num % 1 else str(int(num))\n",
    "\n",
    "\n",
    "def prep(x, y, mask=None):\n",
    "    \"\"\"Prepares data for use in a sklearn model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: xarray.DataArray\n",
    "        an array containing the explanatory data. Can contain more than one\n",
    "        band.\n",
    "    y: xarray.DataArray\n",
    "        an array with a single band containing the response variable\n",
    "    mask: numpy.array\n",
    "        an array used to mask x and y\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of xarray.DataArray\n",
    "        x and y formatted for use in a sklean model\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    \n",
    "    # Ignore areas within scar that did not burn\n",
    "    if mask is not None:\n",
    "        x = x.where(mask)\n",
    "        y = y.where(mask)\n",
    "\n",
    "    # Convert to 1D arrays\n",
    "    x = np.array([np.ravel(b) for b in x])\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    # Limit to values that are finite in all arrays\n",
    "    xy_mask = y.copy()\n",
    "    for band in x:\n",
    "        xy_mask *= band\n",
    "\n",
    "    x = np.array([b[np.isfinite(xy_mask)] for b in x])\n",
    "    y = y[np.isfinite(xy_mask)]\n",
    "    \n",
    "    return x.transpose(), y\n",
    "\n",
    "\n",
    "def slugify(val):\n",
    "    \"\"\"Makes a string suitable for a filename\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    val: str\n",
    "        the string to base the filename on\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the string as a filename\n",
    "    \"\"\"\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", val.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777f7c4",
   "metadata": {},
   "source": [
    "## Configure model\n",
    "\n",
    "The constants in the cell belowâ€”`FEATURES`, `LABELS`, `CLASSIFIER`, `CLASSIFIER_PARAMS`, and `SAMPLING PARAMS`â€”are used to configure how the model will run. At the end of the notebook, the notebook saves the content of each variable along with the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb02b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "FEATURES = [\n",
    "    # Vegetation\n",
    "    \"Community\",\n",
    "    #\"FAL\",\n",
    "    \"Dead\",\n",
    "    #\"dFAL\",\n",
    "    #\"Years Dead\",\n",
    "    #\"Burned (2000-2018)\",\n",
    "    \n",
    "    # Pre-fire spectral indices\n",
    "    #\"LFMC\",\n",
    "    #\"NDVI\",\n",
    "    #\"NDMI\",\n",
    "    \"NDWI\",\n",
    "    #\"SAVI\",\n",
    "    \n",
    "    # Topography\n",
    "    \"Elevation\",\n",
    "    #\"Aspect\",\n",
    "    \"Folded Aspect\",\n",
    "    \"Slope\",\n",
    "    \n",
    "    # Climate\n",
    "    #\"Days Precipitation\",\n",
    "    #\"Max VPD\",\n",
    "    #\"Min Temperature\",\n",
    "    #\"Heat Days Over 95\",\n",
    "    #\"Cumulative Precipitation\",\n",
    "    \n",
    "    # Burn severity\n",
    "    #\"dNBR\",\n",
    "    #\"Classified dNBR\",\n",
    "]\n",
    "\n",
    "# Response variable. Must be either \"Classified dNBR\" or \"Dead Pixels\".\n",
    "LABELS = \"Classified dNBR\"\n",
    "\n",
    "# Class of classifier\n",
    "CLASSIFIER = RandomForestClassifier\n",
    "\n",
    "# Keyword arguments passed to classifier. If this dict is empty, the notebook\n",
    "# will tune the classifier based on a set of reasonable parameters using the\n",
    "# GridSearchCV function. This is very slow, so provide params if you can.\n",
    "CLASSIFIER_PARAMS = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_samples_leaf\": 10,\n",
    "    \"max_features\": \"log2\",\n",
    "    \"oob_score\": True,\n",
    "}\n",
    "\n",
    "# Keyword arguments pass to create_sampling_mask\n",
    "SAMPLING_PARAMS = {\n",
    "    \"counts\": {\"training\": 9000, \"validation\": 3000},\n",
    "    #\"balanced\": True,\n",
    "    \"seed\": 20210421\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b79a7b",
   "metadata": {},
   "source": [
    "## Restore and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stored ready variable and run load-data.ipynb if not found\n",
    "%store -r woolsey_data_ready\n",
    "try:\n",
    "    woolsey_data_ready\n",
    "except NameError:\n",
    "    print(\"Running load-data.ipynb...\")\n",
    "    run_notebook(\"load-data.ipynb\")\n",
    "\n",
    "# Retore variables using storemagic. Each variable is restored explicitly to\n",
    "# avoid confusion about where variable names are coming from.    \n",
    "%store -r all_data\n",
    "%store -r cmap_dnbr\n",
    "%store -r labels_dnbr\n",
    "%store -r prism_grid\n",
    "%store -r reproj_to\n",
    "%store -r woolsey_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ca452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lookup for all data\n",
    "datasets = all_data.copy()\n",
    "\n",
    "# Use the mean for each pixel for each four-year set of climate data\n",
    "for key in (\n",
    "    \"Days Precipitation\",\n",
    "    \"Max VPD\",\n",
    "    \"Minimum Temperature\",\n",
    "    \"Heat Days Over 95\",\n",
    "    \"Cumulative Precipitation\"\n",
    "):\n",
    "    datasets[key] = datasets[key].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the model to a subset of the available pixels\n",
    "# FIXME: Subset is not captured when model is saved\n",
    "cond = (\n",
    "    (datasets[\"Classified dNBR\"] > 1)    # ignore unburned\n",
    "    & (datasets[\"Classified dNBR\"] < 5)  # ignore increased greenness\n",
    "    & (datasets[\"Community\"] != 6)       # ignore substrate\n",
    ")\n",
    "mask = xr.where(cond, True, False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and verify the sampling mask\n",
    "xda = reproj_to.rio.clip(woolsey_fire.geometry)\n",
    "sampling_mask = create_sampling_mask(xda, **SAMPLING_PARAMS)\n",
    "\n",
    "# Verify that the sampling mask is the right shape\n",
    "if sampling_mask.shape[-2:] != prism_grid.shape[-2:]:\n",
    "    raise ValueError(\"Invalid shape\")\n",
    "\n",
    "# Create training and validation subsets\n",
    "training = {k: v.where(sampling_mask[0]) for k, v in datasets.items()}\n",
    "validation = {k: v.where(sampling_mask[1]) for k, v in datasets.items()}\n",
    "\n",
    "# Create lookup for all subsets\n",
    "subsets = {\n",
    "    \"all\": datasets,\n",
    "    \"training\": training,\n",
    "    \"validation\": validation,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae2369",
   "metadata": {},
   "source": [
    "## Run the random-forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters if no parameters provided for the classifier\n",
    "if not CLASSIFIER_PARAMS:\n",
    "    \n",
    "    param_grid = {\n",
    "        \"min_samples_leaf\": [1, 10, 25],\n",
    "        \"max_depth\": [5, 10, None],\n",
    "        \"max_features\": [\"auto\", \"log2\"],\n",
    "        \"n_estimators\": [100, 500]\n",
    "    }\n",
    "\n",
    "    classifier = CLASSIFIER()\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=classifier,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    grid_search.fit(tx, ty)\n",
    "    CLASSIFIER_PARAMS = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature and label datasets\n",
    "features = sorted([f for f in FEATURES if f != LABELS])\n",
    "\n",
    "xdata = {}\n",
    "for subset, lookup in subsets.items():\n",
    "    \n",
    "    bands = []\n",
    "    for key in features:\n",
    "        band = lookup[key]\n",
    "        \n",
    "        # If more than one layer, use the last one. You can get around this\n",
    "        # behavior by selecting a layer or aggregating all layers above (for\n",
    "        # example, climate data uses the mean of the four years).\n",
    "        if len(band.shape) > 2:\n",
    "            band = band[-1]\n",
    "        \n",
    "        bands.append(band)\n",
    "        \n",
    "        try:\n",
    "            del bands[-1][\"band\"]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        bands[-1] = bands[-1].squeeze()\n",
    "        bands[-1][\"band\"] = len(bands)\n",
    "        \n",
    "    xdata[subset] = xr.concat(bands, dim=\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation splits\n",
    "tx, ty = prep(xdata[\"training\"], training[LABELS], mask)\n",
    "vx, vy = prep(xdata[\"validation\"], validation[LABELS], mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pair plots of training data\n",
    "paired = pd.DataFrame(data=tx, columns=features)\n",
    "paired[\"response\"] = ty\n",
    "\n",
    "# Suppress warnings from pair plot. The pair plot function throws a lot of\n",
    "# warnings based on the source data, but they aren't useful.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    sns.pairplot(paired,\n",
    "                 height=5,\n",
    "                 plot_kws={\"s\": 100},\n",
    "                 hue=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model multiple times to assess performance\n",
    "runs = []\n",
    "for i in range(20):\n",
    "    classifier = CLASSIFIER(**CLASSIFIER_PARAMS)\n",
    "    classifier.fit(tx, ty)\n",
    "    \n",
    "    # Calculate F1 score for low, moderate, and high severity pixels\n",
    "    f1_scores = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    for i in (2, 3, 4):\n",
    "        mask = np.where(vy == i, True, False)\n",
    "        predicted = classifier.predict(vx[mask])\n",
    "        f1_scores.append(f1_score(vy[mask], predicted, average=\"micro\"))\n",
    "        #recall.append(recall_score(vy[mask], predicted, average=\"micro\"))\n",
    "        #precision.append(precision_score(vy[mask], predicted, average=\"micro\"))\n",
    "    \n",
    "    run = [\n",
    "        classifier.oob_score_,\n",
    "        classifier.score(vx, vy),\n",
    "        mean_squared_error(vy, classifier.predict(vx)) ** 0.5,\n",
    "    ]\n",
    "    run.extend(f1_scores)\n",
    "    run.extend(recall)\n",
    "    run.extend(precision)\n",
    "    run.extend(classifier.feature_importances_)\n",
    "    \n",
    "    runs.append(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ab882",
   "metadata": {},
   "source": [
    "## Summarize and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results from each run\n",
    "cols = [\n",
    "    \"oob\",\n",
    "    \"score\",\n",
    "    \"rmse\",\n",
    "    \"f1_low\",\n",
    "    \"f1_mod\",\n",
    "    \"f1_high\",\n",
    "    #\"recall_low\",\n",
    "    #\"recall_mod\",\n",
    "    #\"recall_high\",\n",
    "    #\"precision_low\",\n",
    "    #\"precision_mod\",\n",
    "    #\"precision_high\",\n",
    "] + [slugify(f\"fi_{f}\") for f in features]\n",
    "results = pd.DataFrame(runs, columns=cols)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfec894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the results from the separate runs\n",
    "agg_results = results.agg([\"mean\", \"std\", \"min\", \"max\", \"count\"])\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "conf_mtx = pd.DataFrame()\n",
    "conf_mtx[\"truth\"] = vy\n",
    "conf_mtx[\"predict\"] = classifier.predict(vx)\n",
    "\n",
    "# Cross-tabulate predictions\n",
    "crosstab = pd.crosstab(conf_mtx[\"truth\"], conf_mtx[\"predict\"], margins=True)\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780890be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the full dataset\n",
    "x = np.array([np.ravel(b) for b in xdata[\"all\"]])\n",
    "x[~np.isfinite(x)] = -9999\n",
    "y = classifier.predict(x.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba0630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model prediction compared to original values\n",
    "\n",
    "# Create a plottable copy of the truth data\n",
    "truth = datasets[LABELS].copy()\n",
    "truth = truth.rio.clip(woolsey_fire.geometry)\n",
    "truth = truth.where(truth != -9999, np.nan)\n",
    "\n",
    "# Create a plottable copy of the model prediction\n",
    "prediction = y.copy()\n",
    "prediction = prediction.reshape(*datasets[LABELS].shape)\n",
    "prediction = copy_xr_metadata(datasets[LABELS], prediction)\n",
    "prediction = prediction.rio.clip(woolsey_fire.geometry)\n",
    "\n",
    "mask = xr.where(cond, True, False).values\n",
    "truth = truth.where(mask)\n",
    "prediction = prediction.where(mask)\n",
    "\n",
    "vmin = truth.min()\n",
    "vmax = truth.max()\n",
    "\n",
    "vmin = 1\n",
    "vmax = 5\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n",
    "fig.suptitle(f\"Random Forest - {LABELS}\\n{', '.join(features)}\")\n",
    "\n",
    "plot_bands(truth,\n",
    "           ax=ax1,\n",
    "           title=\"Measured\",\n",
    "           cmap=cmap_dnbr,\n",
    "           vmin=vmin,\n",
    "           vmax=vmax,\n",
    "           cbar=False,\n",
    "           scale=False)\n",
    "\n",
    "plot_bands(prediction,\n",
    "           ax=ax2,\n",
    "           title=\"Predicted\",\n",
    "           cmap=cmap_dnbr,\n",
    "           vmin=vmin,\n",
    "           vmax=vmax,\n",
    "           cbar=False,\n",
    "           scale=False)\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    woolsey_fire.plot(ax=ax, facecolor=\"none\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "ep.draw_legend(im_ax=ax1.get_images()[0],\n",
    "               classes=range(5),\n",
    "               titles=labels_dnbr,\n",
    "               bbox=(0.01, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93672613",
   "metadata": {},
   "source": [
    "## Save model parameters and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect parameters in a dict\n",
    "model = {\n",
    "    \"classifier\": CLASSIFIER.__name__,\n",
    "    \"features\": features,\n",
    "    \"labels\": LABELS,\n",
    "    \"params\": {\n",
    "        \"classifier_params\": CLASSIFIER_PARAMS,\n",
    "        \"sampling_params\": SAMPLING_PARAMS}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739275d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model parameters to create a directory for this run\n",
    "json_model = json.dumps(model, sort_keys=True).encode(\"utf-8\")\n",
    "md5_hash = hashlib.md5(json_model).hexdigest()\n",
    "dirname = f\"{agg_results['rmse']['mean']:.3f}_{md5_hash}\".replace(\"0.\", \"\")\n",
    "outdir = os.path.join(\"models\", dirname)\n",
    "\n",
    "try:\n",
    "    os.makedirs(outdir)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save map as PNG\n",
    "fig.savefig(os.path.join(outdir, \"map.png\"), bbox_inches=\"tight\")\n",
    "with open(os.path.join(outdir, \"model.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(model, f, indent=2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4bd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save crosstab and result tables as HTML\n",
    "css = (\n",
    "    \"<style>\"\n",
    "    \"table {border-collapse: collapse;}\"\n",
    "    \"td, th { text-align: center; padding: 8px; }\"\n",
    "    \"th { background-color: #eee; }\"\n",
    "    \"</style>\"\n",
    ")\n",
    "\n",
    "html = crosstab.transpose().to_html(float_format=float_format)\n",
    "with open(os.path.join(outdir, \"crosstab.htm\"), \"w\") as f:\n",
    "    f.write(css + \"\\n\" + html)\n",
    "\n",
    "html = agg_results.transpose().to_html(float_format=float_format)\n",
    "with open(os.path.join(outdir, \"results.htm\"), \"w\") as f:\n",
    "    f.write(css + \"\\n\" + html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34afca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampling masks as PNG\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 16))\n",
    "plot_bands(sampling_mask[0], ax=ax1, cbar=None, title=\"Training\")\n",
    "plot_bands(sampling_mask[1], ax=ax2, cbar=None, title=\"Validation\")\n",
    "for ax in (ax1, ax2):\n",
    "    woolsey_fire.plot(ax=ax, facecolor=\"none\", edgecolor=\"gray\", linewidth=1)\n",
    "fig.savefig(os.path.join(outdir, \"sampling_masks.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save histograms of labels as PNG\n",
    "response = np.array([a[LABELS] for a in [datasets, training, validation]])\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "for ax, arr, title in (zip(axes, response, [\"All\", \"Training\", \"Validation\"])):\n",
    "    counts = {}\n",
    "    for val in np.unique(arr[np.isfinite(arr)]):\n",
    "        counts[val] = np.sum(arr == val)\n",
    "    ax.bar(counts.keys(), counts.values())\n",
    "    ax.set(title=title, xlabel=\"bin\", ylabel=\"counts\")\n",
    "\n",
    "fig.savefig(os.path.join(outdir, \"sampling_histograms.png\"),\n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41dc50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
